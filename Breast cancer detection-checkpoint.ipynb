{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a795ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "INPUT_DATASET = \"datasets/original\"\n",
    "BASE_PATH = \"datasets/idc\"\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4ef542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set\n",
      "Building directory datasets/idc\\training\n",
      "Building directory datasets/idc\\training\\0\n",
      "Building directory datasets/idc\\training\\1\n",
      "Building validation set\n",
      "Building directory datasets/idc\\validation\n",
      "Building directory datasets/idc\\validation\\1\n",
      "Building directory datasets/idc\\validation\\0\n",
      "Building testing set\n",
      "Building directory datasets/idc\\testing\n",
      "Building directory datasets/idc\\testing\\1\n",
      "Building directory datasets/idc\\testing\\0\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import random\n",
    "\n",
    "originalPaths = list(paths.list_images(INPUT_DATASET))\n",
    "random.seed(7)\n",
    "random.shuffle(originalPaths)\n",
    "index = int(len(originalPaths) * TRAIN_SPLIT)\n",
    "trainPaths = originalPaths[:index]\n",
    "testPaths = originalPaths[index:]\n",
    "index = int(len(trainPaths) * VAL_SPLIT)\n",
    "valPaths = trainPaths[:index]\n",
    "trainPaths = trainPaths[index:]\n",
    "datasets = [(\"training\", trainPaths, TRAIN_PATH),\n",
    "            (\"validation\", valPaths, VAL_PATH),\n",
    "            (\"testing\", testPaths, TEST_PATH)\n",
    "            ]\n",
    "for (setType, originalPaths, basePath) in datasets:\n",
    "    print(f'Building {setType} set')\n",
    "    if not os.path.exists(basePath):\n",
    "        print(f'Building directory {basePath}')\n",
    "        os.makedirs(basePath)\n",
    "    for path in originalPaths:\n",
    "        file = path.split(os.path.sep)[-1]\n",
    "        label = file[-5:- 4]\n",
    "        labelPath = os.path.sep.join([basePath, label])\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(f'Building directory {labelPath}')\n",
    "            os.makedirs(labelPath)\n",
    "        newPath = os.path.sep.join([labelPath, file])\n",
    "        shutil.copy2(path, newPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c945a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "class CancerNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = keras.models.Sequential()\n",
    "        shape = (height, width, depth)\n",
    "        channelDim = -1\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            input_shape = (depth, height, width)\n",
    "            channelDim = 1\n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=shape))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=classes, activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57fd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199818 images belonging to 2 classes.\n",
      "Found 199818 images belonging to 2 classes.\n",
      "Found 22201 images belonging to 2 classes.\n",
      "Found 55505 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "6245/6245 [==============================] - 679s 108ms/step - loss: 0.3725 - accuracy: 0.8418 - val_loss: 0.6261 - val_accuracy: 0.7276\n",
      "Epoch 2/2\n",
      " 617/6245 [=>............................] - ETA: 1:09:12 - loss: 0.3479 - accuracy: 0.8509"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory('datasets/idc/training', target_size=(64, 64), batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "trainPaths = list(paths.list_images(TRAIN_PATH))\n",
    "lenTrain = len(trainPaths)\n",
    "lenVal = len(list(paths.list_images(VAL_PATH)))\n",
    "lenTest = len(list(paths.list_images(TEST_PATH)))\n",
    "\n",
    "trainLabels = [int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels = to_categorical(trainLabels)\n",
    "classTotals = trainLabels.sum(axis=0)\n",
    "classWeight = classTotals.max() / classTotals\n",
    "\n",
    "trainAug = ImageDataGenerator(rescale=1 / 255.0, rotation_range=20, zoom_range=0.05, width_shift_range=0.1,\n",
    "height_shift_range=0.1, shear_range=0.05, horizontal_flip=True, vertical_flip=True,\n",
    "                              fill_mode=\"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(TRAIN_PATH, class_mode=\"categorical\", target_size=(48, 48), color_mode=\"rgb\",\n",
    "                                        shuffle=True, batch_size=BS)\n",
    "valGen = valAug.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS)\n",
    "testGen = valAug.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS)\n",
    "model = CancerNet.build(width=48, height=48, depth=3, classes=2)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "M = model.fit(x=trainGen, validation_data=valGen, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc678c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now evaluating the model\")\n",
    "testGen.reset()\n",
    "pred_indices = model.predict_generator(testGen, steps=(lenTest // BS) + 1)\n",
    "\n",
    "pred_indices = np.argmax(pred_indices, axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm = confusion_matrix(testGen.classes, pred_indices)\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / total\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), M.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), M.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), M.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), M.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on the IDC Dataset\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05ddf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e7c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
